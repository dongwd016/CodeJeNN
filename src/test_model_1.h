#include <iostream>
#include <array>
#include <random>
#include <cmath>

template<typename Scalar>
using activationFunction = void(*)(Scalar*, const Scalar*, size_t, Scalar);

// - -

template<typename Scalar>
void relu(Scalar* outputs, const Scalar* inputs, size_t size, Scalar alpha = 0.0) noexcept {
    for (size_t i = 0; i < size; ++i) {
        outputs[i] = inputs[i] > 0 ? inputs[i] : 0;
    }
}

template<typename Scalar>
void linear(Scalar* outputs, const Scalar* inputs, size_t size, Scalar alpha = 0.0) noexcept {
    for (size_t i = 0; i < size; ++i) {
        outputs[i] = inputs[i];
    }
}

template<typename Scalar>
void addBias(Scalar* outputs, const Scalar* biases, int size) noexcept {
    for (int i = 0; i < size; i++) {
        outputs[i] += biases[i];
    }
}

template<typename Scalar>
void dotProduct(Scalar* outputs, const Scalar* inputs, const Scalar* weights, int input_size, int output_size) noexcept {
    for (int i = 0; i < output_size; i++) {
        outputs[i] = 0;
        for (int j = 0; j < input_size; j++) {
            outputs[i] += inputs[j] * weights[j * output_size + i];
        }
    }
}

template<typename Scalar, int output_size>
void forwardPropagation(Scalar* outputs, const Scalar* inputs, const Scalar* weights, const Scalar* biases, int input_size, void (*activation_function)(Scalar*, const Scalar*, size_t, Scalar), Scalar alpha) noexcept {
    std::array<Scalar, output_size> temp_outputs;
    dotProduct(temp_outputs.data(), inputs, weights, input_size, output_size);
    addBias(temp_outputs.data(), biases, output_size);
    activation_function(outputs, temp_outputs.data(), output_size, alpha);
}

// - -

template <typename Scalar = double>
auto test_model_1(const std::array<Scalar, 10>& initial_input) {

    std::array<Scalar, 10> input_norms = {9.783506673e-01, 9.950856503e-01, 9.911147200e-01, 9.481037490e-01, 9.701938376e-01, 9.837677445e-01, 9.746474191e-01, 9.860366004e-01, 9.822145455e-01, 9.460183203e-01};

    std::array<Scalar, 10> input_mins = {1.215447469e-02, 4.632023005e-03, 5.522117124e-03, 1.454466567e-02, 1.545661653e-02, 9.197051617e-03, 1.135364477e-02, 1.083765148e-02, 5.061583846e-03, 4.086861627e-02};

    std::array<Scalar, 10> model_input;
    for (int i = 0; i < 10; i++) { model_input[i] = (initial_input[i] - input_mins[i]) / (input_norms[i]); }

    if (model_input.size() != 10) { throw std::invalid_argument("Invalid input size. Expected size: 10"); } 

    // - -

    std::array<Scalar, 80> weights_1 = {3.838323057e-01, -1.214287877e+00, 1.503241807e-01, 6.117594615e-02, -1.099729165e-01, -3.874695599e-01, 3.951810598e-01, 3.523450196e-01, -3.079867363e-01, 7.362986207e-01, 5.244294405e-01, -6.495398283e-01, 3.584980071e-01, 5.278286338e-01, 5.698761344e-01, 3.890236141e-03, -4.821486771e-01, -5.069726110e-01, 5.241883919e-02, -2.222042233e-01, -3.403284550e-01, 4.259140491e-01, 3.746453524e-01, -5.247475579e-02, 4.832874238e-01, -5.599290729e-01, -2.422035187e-01, 2.091293782e-01, 4.938834906e-01, 5.916922092e-01, 3.903810978e-01, 1.102927178e-01, -2.451898158e-01, -7.146394849e-01, -1.791516095e-01, 4.665245116e-02, -3.347629681e-02, 2.809750140e-01, -2.979745530e-02, 1.999252290e-01, 2.748666108e-01, 5.582695603e-01, 5.544155836e-01, -1.010912433e-01, -5.989718437e-01, -3.844061494e-01, 4.987213016e-01, 1.665758938e-01, 5.155239701e-01, 3.272857964e-01, -3.640299737e-01, 7.396921515e-01, -6.575121284e-01, -2.725988328e-01, 4.673021138e-01, -6.768412590e-01, 1.394847482e-01, -8.425017595e-01, -3.633658886e-01, 2.712722421e-01, 1.006742790e-01, -3.633521199e-01, -8.263250440e-02, -3.518971205e-01, -1.222931147e-01, 4.312294126e-01, 1.901188120e-02, -4.278780147e-02, -4.250619709e-01, -4.380883873e-01, 4.476489425e-01, -4.080758095e-01, -3.979187608e-01, -1.658702940e-01, 7.452940941e-01, -4.261493683e-01, -1.920003742e-01, 4.983290732e-01, -4.515365064e-01, -6.880332232e-01};

    std::array<Scalar, 8> biases_1 = {6.672031432e-02, 6.763626635e-02, 2.183249444e-01, 2.678788602e-01, 4.475956559e-01, -4.781104624e-02, -2.159741707e-02, 1.195950881e-01};

    std::array<Scalar, 128> weights_2 = {1.058221236e-01, -3.191058040e-01, 4.885166287e-01, 3.720068634e-01, 7.549945731e-03, 2.952747345e-01, 8.961323649e-02, 2.012212425e-01, 1.573946476e-01, 4.358364046e-01, 5.415731668e-01, -2.850009203e-01, -6.533969641e-01, -2.333678752e-01, -2.324726284e-01, -3.834831715e-01, -7.202962637e-01, -8.650959730e-01, -8.779998422e-01, -9.782754630e-02, 1.597461104e-01, -1.525536299e+00, -5.926596522e-01, 1.753393114e-01, 8.541008830e-02, 1.421395242e-01, 1.786693335e+00, 1.991108656e-01, -8.593729883e-02, 5.631100014e-02, -7.232081294e-01, -4.300853014e-01, -2.317056507e-01, 4.060410708e-02, 2.444614023e-01, -5.154314041e-01, -4.296139479e-01, 4.840442836e-01, 5.525744557e-01, -7.158235461e-02, 3.583090305e-01, -2.271678895e-01, -1.005275488e+00, 1.166266203e-01, 4.144501686e-01, -1.503187418e-01, 1.708609611e-01, -4.942811728e-01, 1.425829679e-01, 1.736737788e-01, 7.239428163e-01, 2.879225612e-01, -1.550900787e-01, -2.216112137e+00, -1.595292538e-01, -1.012839526e-01, 2.402116507e-01, -2.287619114e-01, 1.118935645e-01, -1.676046848e-01, 1.124627709e+00, 8.295240402e-01, 1.748233289e-01, 6.002366543e-02, -2.056157112e+00, 1.065532923e+00, 4.225672185e-01, -5.360776186e-02, -4.021581113e-01, -9.943930507e-01, -4.851994663e-02, -1.091737151e+00, 1.027642265e-01, 1.256229401e+00, 3.642356098e-01, -4.573308229e-01, -9.429576993e-02, 3.471249044e-01, 2.883307338e-01, -3.986170292e-01, 3.413735330e-02, 2.442378998e-01, 1.271244437e-01, 2.725602984e-01, 2.758959234e-01, -6.430316567e-01, -3.379074633e-01, -3.243881166e-01, -4.942073822e-01, -6.151602864e-01, 4.214669466e-01, -1.283905506e-01, 4.725005031e-01, -6.994750500e-01, 2.252366692e-01, -2.600148916e-01, 3.465926349e-01, 2.935407460e-01, -1.497379094e-01, -1.777433306e-01, -1.323146820e-01, -6.397759914e-01, 3.993934952e-03, 1.969718188e-01, 1.638533026e-01, 2.404581904e-01, -4.908597469e-01, -3.645536900e-01, -7.793976665e-01, 2.880373001e-01, 1.278350204e-01, -3.031066656e-01, -1.081924081e+00, -3.342464566e-01, 4.644070938e-02, -1.195496917e-01, 2.509987056e-01, -3.039907217e-01, 7.697668672e-02, -5.988723040e-02, -1.206778586e-01, 4.202219844e-01, -4.823545814e-01, 5.051624775e-02, -1.157345772e-01, -2.694101632e-01, 1.562202536e-02, -3.220915794e-03};

    std::array<Scalar, 16> biases_2 = {3.702647984e-02, 5.696909130e-02, 8.121879399e-02, -5.910016224e-02, -4.234668985e-02, 6.100555658e-01, 2.201989144e-01, -3.129526973e-03, 1.105245650e-01, -4.745358601e-02, 1.988155842e-01, 0.000000000e+00, -3.821500577e-03, 1.937196217e-02, -6.618992984e-02, 0.000000000e+00};

    std::array<Scalar, 128> weights_3 = {-1.196188927e-01, -5.876848698e-01, 2.596911192e-01, -1.870310158e-01, -7.219338417e-01, 4.881379008e-02, -5.210384130e-01, 2.748639584e-01, -1.098816395e-01, -9.645273536e-02, 3.866185844e-01, 5.042306781e-01, 3.432094753e-01, 1.553480513e-02, -4.614624679e-01, -5.259631872e-01, -1.651630402e-01, -2.571926117e-01, -7.560787797e-01, 1.269494742e-01, 7.841727883e-02, -5.110252500e-01, 3.926836252e-01, -3.987147808e-01, 3.939731121e-01, 5.522207618e-01, -1.397858113e-01, -1.314383894e-01, -5.713360906e-01, 8.221665025e-02, -3.957158327e-01, -2.054645866e-01, 1.469105482e-01, 1.846065223e-01, -7.585439086e-02, 1.609853804e-01, -3.536673486e-01, 2.033390999e-01, 5.932450294e-02, 7.474198937e-02, -1.863838434e-01, 9.493704140e-02, -2.194846392e+00, 1.288761973e+00, -2.490347147e+00, -3.049296737e-01, -4.560428858e-01, -3.598729670e-01, -3.492257595e-01, -2.209802568e-01, 2.917326987e-01, -2.549170256e-01, 7.011655569e-01, -3.014049530e-01, 3.913903534e-01, -3.362026811e-01, -4.070481062e-01, -4.207588434e-01, 2.639616430e-01, -3.605808914e-01, -2.333495915e-01, 2.526000738e-01, 1.459731907e-01, 1.464711875e-01, -2.533463240e-01, 3.538899720e-01, -1.975616217e-01, 1.169571653e-01, 5.785358548e-01, -1.991330236e-01, -4.556598663e-01, 3.277305961e-01, 1.008367538e-02, 4.272441566e-01, -1.814417541e-01, -5.024562478e-01, -2.181216627e-01, 2.348969132e-01, 2.541776896e-01, 4.626266658e-01, -4.777979851e-02, -6.998074651e-01, -2.409458458e-01, 1.176891446e+00, 4.748987556e-01, 1.203690648e+00, -3.801578283e-01, 5.651845038e-02, -4.612706900e-01, -1.128265858e-01, 3.411275148e-01, -2.309261560e-01, 2.924022675e-01, 2.679202557e-01, -1.761187315e-01, -4.301135540e-01, 1.292786598e-01, -2.530488372e-01, -7.445658445e-01, -1.720988750e+00, -1.943770945e-01, -4.230363667e-01, -1.466774940e-01, -5.044447184e-01, -4.376087189e-01, 5.208556056e-01, -1.288202554e-01, 3.893545866e-01, 6.556716561e-01, 4.064733088e-01, -4.840851724e-01, -3.445104882e-02, -3.063964844e-01, 1.241753101e-01, 2.396318913e-01, 4.847156405e-01, 1.344796121e-01, -6.238627061e-02, -3.541593850e-01, 4.150878787e-01, 4.764900208e-01, 4.577465057e-01, 4.295194149e-02, 2.168992758e-01, -1.523532867e-01, -3.462442160e-01, -4.384112358e-02, 3.560630083e-01};

    std::array<Scalar, 8> biases_3 = {0.000000000e+00, -5.483426154e-02, -4.829139262e-02, -2.008102089e-02, 1.400978565e-01, -5.011248589e-02, -5.256697163e-02, -2.524208464e-02};

    std::array<Scalar, 40> weights_4 = {-1.010395885e-01, -6.338006258e-02, -7.279688120e-02, 5.430800915e-01, -2.780568898e-01, -3.047494590e-01, -5.999616385e-01, 4.755472019e-02, 1.096146464e+00, 5.513872504e-01, -6.064042449e-01, -2.816049196e-02, 2.645253241e-01, 1.265843064e-01, -5.194566846e-01, -1.027526855e-01, 5.015496016e-01, 1.078710333e-01, 7.371251583e-01, 5.743381977e-01, 4.562885463e-01, 3.609379530e-01, 4.769901335e-01, 2.248416394e-01, 4.193646014e-01, -1.975158453e-01, -7.157263905e-02, -3.432815969e-01, -7.015939951e-01, -1.756525636e-01, -2.331030369e-01, 7.207647711e-02, 1.451750994e-01, -4.145485163e-01, 1.092653200e-01, 7.002360374e-02, -5.733631849e-01, -3.860035837e-01, 6.289409995e-01, 4.527163208e-01};

    std::array<Scalar, 5> biases_4 = {2.374257147e-01, 2.451499552e-02, 3.982899338e-02, 3.949124366e-03, -3.195601702e-02};

    // - -

    std::array<Scalar, 8> layer_1_output;
    forwardPropagation<Scalar, 8>(layer_1_output.data(), model_input.data(), weights_1.data(), biases_1.data(), 10, &relu<Scalar>, 0.0);

    std::array<Scalar, 16> layer_2_output;
    forwardPropagation<Scalar, 16>(layer_2_output.data(), layer_1_output.data(), weights_2.data(), biases_2.data(), 8, &relu<Scalar>, 0.0);

    std::array<Scalar, 8> layer_3_output;
    forwardPropagation<Scalar, 8>(layer_3_output.data(), layer_2_output.data(), weights_3.data(), biases_3.data(), 16, &relu<Scalar>, 0.0);

    std::array<Scalar, 5> layer_4_output;
    forwardPropagation<Scalar, 5>(layer_4_output.data(), layer_3_output.data(), weights_4.data(), biases_4.data(), 8, &linear<Scalar>, 0.0);

    std::array<Scalar, 5> output_norms = {9.414215042e-01, 9.827280271e-01, 9.645390417e-01, 9.905752556e-01, 9.877931859e-01};

    std::array<Scalar, 5> output_mins = {2.997358987e-02, 4.939980934e-03, 2.212355153e-02, 5.758660498e-03, 1.162053991e-02};

    std::array<Scalar, 5> model_output;
    for (int i = 0; i < 5; i++) { model_output[i] = (layer_4_output.data()[i] * output_norms[i]) + output_mins[i]; } 

    return model_output;
}
